import numpy as np 
# Define the initial weights and biases 
w1 = 0.4 
w2 = -0.3 
w3 = 0.1 
w4 = -0.2 

b1 = 0.1 
b2 = 0.2 
b3 = -0.1 
# Define the input and target output 
x = np.array([1]) 
y_true = np.array([1]) 
# Set the tolerance 
tolerance = 0.01 
# Loop until the predicted output is within the tolerance 
while True: 
    # Forward propagation 
    h1 = x * w1 + b1 
    h2 = x * w2 + b2 
    y_pred = h1 * w3 + h2 * w4 + b3 
    # Calculate the error 
    error = y_true - y_pred 

    # If the error is within the tolerance, break out of the loop 
    if abs(error) < tolerance: 
        break 
    # Backpropagation 
    d_y_pred = -2 * error 
    d_w3 = h1 * d_y_pred 
    d_h1 = w3 * d_y_pred 
    d_w4 = h2 * d_y_pred 
    d_h2 = w4 * d_y_pred 
    d_h1[h1 <= 0] = 0 
    d_h2[h2 <= 0] = 0 
    d_w1 = x * d_h1 
    d_b1 = d_h1 
    d_w2 = x * d_h2 
    d_b2 = d_h2 
    # Update the weights and biases 
    learning_rate = 0.1 
    w1 -= learning_rate * d_w1 
    w2 -= learning_rate * d_w2 
    w3 -= learning_rate * d_w3 
    w4 -= learning_rate * d_w4 
    b1 -= learning_rate * d_b1 
    b2 -= learning_rate * d_b2 
    b3 -= learning_rate * d_y_pred 
    # Print the predicted output and all intermediate values on the same line 
    print(f"Predicted output: {y_pred[0]:.2f}, w1: {w1[0]:.2f}, w2: {w2[0]:.2f}, w3: {w3[0]:.2f}, w4: {w4[0]:.2f}, b1: {b1[0]:.2f}, b2: {b2[0]:.2f}, b3: {b3[0]:.2f}, h1: {h1[0]:.2f}, h2: {h2[0]:.2f}, error: {error[0]:.2f}") 
print("Target output reached!")     
print("Input: \n" + str(X))
print("Actual Output: \n" + str(y))
print("Predicted Output: \n" ,output)
